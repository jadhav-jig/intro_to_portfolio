{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import pandas as pd\nimport pandas as pd\n\n# Read in the csv file and parse dates\nStockPrices = pd.read_csv(fpath_csv, parse_dates=['Date'])\n\n# Ensure the prices are sorted by Date\nStockPrices = StockPrices.sort_values(by='Date')\n\n# Print only the first five rows of StockPrices\nprint(StockPrices[0:5])\n\n# Convert the decimal returns into percentage returns\npercent_return = StockPrices['Returns']*100\n\n# Drop the missing values\nreturns_plot = percent_return.dropna()\n\n# Plot the returns histogram\nplt.hist(returns_plot, bins=75)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import numpy as np\nimport numpy as np\n\n# Calculate the average daily return of the stock\nmean_return_daily = np.mean(StockPrices['Returns'])\nprint(mean_return_daily)\n\n# Calculate the implied annualized average return\nmean_return_annualized = ((1+mean_return_daily)**252)-1\nprint(mean_return_annualized)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the standard deviation of daily return of the stock\nsigma_daily = np.std(StockPrices['Returns'])\nprint(sigma_daily)\n\n# Calculate the daily variance\nvariance_daily = sigma_daily**2\nprint(variance_daily)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Annualize the standard deviation\nsigma_annualized = sigma_daily*np.sqrt(252)\nprint(sigma_annualized)\n\n# Calculate the annualized variance\nvariance_annualized = sigma_annualized**2\nprint(variance_annualized)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import skew from scipy.stats\nfrom scipy.stats import skew\n\n# Drop the missing values\nclean_returns = StockPrices['Returns'].dropna()\n\n# Calculate the third moment (skewness) of the returns distribution\nreturns_skewness = skew(clean_returns)\nprint(returns_skewness)\n\n# Import kurtosis from scipy.stats\nfrom scipy.stats import kurtosis\n\n# Calculate the excess kurtosis of the returns distribution\nexcess_kurtosis = kurtosis(clean_returns)\nprint(excess_kurtosis)\n\n# Derive the true fourth moment of the returns distribution\nfourth_moment = excess_kurtosis+3\nprint(fourth_moment)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import shapiro from scipy.stats\nfrom scipy.stats import shapiro\n\n# Run the Shapiro-Wilk test on the stock returns\nshapiro_results = shapiro(clean_returns)\nprint(\"Shapiro results:\", shapiro_results)\n\n# Extract the p-value from the shapiro_results\np_value = shapiro_results[1]\nprint(\"P-value: \", p_value)\n\n'''Shapiro results: ShapiroResult(statistic=0.9003633260726929, pvalue=0.0)\nP-value:  0.0\n\n<script.py> output:\n    Shapiro results: ShapiroResult(statistic=0.9003633260726929, pvalue=0.0)\n    P-value:  0.0 '''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Equal weighted\n\n# Finish defining the portfolio weights as a numpy array\nportfolio_weights = np.array([0.12, 0.15, 0.08, 0.05, 0.09, 0.10, 0.11, 0.14, 0.16])\n\n# Calculate the weighted stock returns (axis=1 means rows)\nWeightedReturns = StockReturns.mul(portfolio_weights, axis=1)\n\n# Calculate the portfolio returns\nStockReturns['Portfolio'] = WeightedReturns.sum(axis=1)\n\n# Plot the cumulative portfolio returns over time\nCumulativeReturns = ((1+StockReturns[\"Portfolio\"]).cumprod()-1)\nCumulativeReturns.plot()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Market weighted\n\n# Create an array of market capitalizations (in billions)\nmarket_capitalizations = np.array([601.51, 469.25, 349.5, 310.48, 299.77, 356.94, 268.88, 331.57, 246.09])\n\n# Calculate the market cap weights\nmcap_weights = market_capitalizations/sum(market_capitalizations)\n\n# Calculate the market cap weighted portfolio returns\nStockReturns['Portfolio_MCap'] = StockReturns.iloc[:, 0:9].mul(mcap_weights, axis=1).sum(axis=1)\ncumulative_returns_plot(['Portfolio', 'Portfolio_EW', 'Portfolio_MCap'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorrelation_matrix = StockReturns.corr()\n\n# Print the correlation matrix\nprint(correlation_matrix)\n\n\n# Import seaborn as sns\nimport seaborn as sns\n\n# Create a heatmap\nsns.heatmap(correlation_matrix,\n            annot=True,\n            cmap=\"YlGnBu\", \n            linewidths=0.3,\n            annot_kws={\"size\": 8})\n\n# Plot aesthetics\nplt.xticks(rotation=90)\nplt.yticks(rotation=0) \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the covariance matrix\ncov_mat = StockReturns.cov()\n\n# Annualize the co-variance matrix\ncov_mat_annual = cov_mat*252\n\n# Print the annualized co-variance matrix\nprint(cov_mat_annual)\n\n#Formula of portfolio volatility is square root of portfolio weight transpose * covariance matrix of returns *portfolio weight\n# Import numpy as np\nimport numpy as np\n\n# Calculate the portfolio standard deviation\nportfolio_volatility = np.sqrt(np.dot(portfolio_weights.T, np.dot(cov_mat_annual, portfolio_weights)))\nprint(portfolio_volatility)\n\n\n# Risk free rate\nrisk_free = 0\n\n# Calculate the Sharpe Ratio for each asset\nRandomPortfolios['Sharpe'] = (RandomPortfolios['Returns']-risk_free)/RandomPortfolios['Volatility']\n\n# Print the range of Sharpe ratios\nprint(RandomPortfolios['Sharpe'].describe()[['min', 'max']])\n\n'''\nOutput:\nmin    0.742884\nmax    2.270462'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Max Sharpe Ratio\n\n# Risk free rate\nrisk_free = 0\n\n# Calculate the Sharpe Ratio for each asset\nRandomPortfolios['Sharpe'] = (RandomPortfolios['Returns']-risk_free)/RandomPortfolios['Volatility']\n\n# Print the range of Sharpe ratios\nprint(RandomPortfolios['Sharpe'].describe()[['min', 'max']])\n\n'''\nOutput:\nmin    0.742884\nmax    2.270462'''\n\n\n# Sort the portfolios by Sharpe ratio\nsorted_portfolios = RandomPortfolios.sort_values(by=['Sharpe'], ascending=False)\n\n# Extract the corresponding weights\nMSR_weights = sorted_portfolios.iloc[0, 0:numstocks]\n\n# Cast the MSR weights as a numpy array\nMSR_weights_array = np.array(MSR_weights)\n\n# Calculate the MSR portfolio returns\nStockReturns['Portfolio_MSR'] = StockReturns.iloc[:, 0:numstocks].mul(MSR_weights_array, axis=1).sum(axis=1)\n\n# Plot the cumulative returns\ncumulative_returns_plot(['Portfolio_EW', 'Portfolio_MCap', 'Portfolio_MSR'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Global Minimum Volatile Portfolio\n\n# Sort the portfolios by volatility\nsorted_portfolios = RandomPortfolios.sort_values(by=['Volatility'], ascending=True)\n\n# Extract the corresponding weights\nGMV_weights = sorted_portfolios.iloc[0, 0:numstocks]\n\n# Cast the GMV weights as a numpy array\nGMV_weights_array = np.array(GMV_weights)\n\n# Calculate the GMV portfolio returns\nStockReturns['Portfolio_GMV'] = StockReturns.iloc[:, 0:numstocks].mul(GMV_weights_array, axis=1).sum(axis=1)\n\n# Plot the cumulative returns\ncumulative_returns_plot(['Portfolio_EW', 'Portfolio_MCap', 'Portfolio_MSR', 'Portfolio_GMV'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Excess returns\n**The portfolio return minus the risk-free rate of return is known as the Excess Portfolio Return.**","metadata":{}},{"cell_type":"code","source":"# Calculate excess portfolio returns\nFamaFrenchData['Portfolio_Excess'] = FamaFrenchData['Portfolio']-FamaFrenchData['RF']\n\n# Plot returns vs excess returns\nCumulativeReturns = ((1+FamaFrenchData[['Portfolio','Portfolio_Excess']]).cumprod()-1)\nCumulativeReturns.plot()\nplt.show()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculating beta using co-variance","metadata":{}},{"cell_type":"code","source":"#Calculating beta using co-variance\n\n# Calculate the co-variance matrix between Portfolio_Excess and Market_Excess\ncovariance_matrix = FamaFrenchData[['Portfolio_Excess', 'Market_Excess']].cov()\n\n# Extract the co-variance co-efficient\ncovariance_coefficient = covariance_matrix.iloc[0, 1]\nprint(covariance_coefficient)\n\n# Calculate the benchmark variance\nbenchmark_variance = FamaFrenchData['Market_Excess'].var()\nprint(benchmark_variance)\n\n# Calculating the portfolio market beta\nportfolio_beta = covariance_coefficient/benchmark_variance\nprint(portfolio_beta)\n\n'''Your portfolio beta is 0.9738. You can think of market beta as a measure of your exposure to the broad stock market. \nFor every 1.0% rise (or fall) in the market, you can expect your portfolio to rise (fall) roughly 0.97%.'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Calculating beta with CAPM**\n","metadata":{}},{"cell_type":"code","source":"# Import statsmodels.formula.api\nimport statsmodel.formula.api as smf \n\n# Define the regression formula\nCAPM_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess', data=FamaFrenchData)\n\n# Print adjusted r-squared of the fitted regression\nCAPM_fit = CAPM_model.fit()\nprint(CAPM_fit.rsquared_adj)\n\n# Extract the beta\nregression_beta = CAPM_fit.params['Market_Excess']\nprint(regression_beta)\n\n#0.7942627160017834\n\n'''Your portfolio beta is once again 0.9738. The adjusted r-squared is 0.7943. \nA high adjusted r-squared (close to 1) means that the majority of your portfolio's movements can be explained by the factors in your model.'''\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Fama French 3-factor model\n","metadata":{}},{"cell_type":"code","source":"# Import statsmodels.formula.api\nimport statsmodels.formula.api as smf \n\n# Define the regression formula\nFamaFrench_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess + SMB + HML', data=FamaFrenchData)\n\n# Fit the regression\nFamaFrench_fit = FamaFrench_model.fit()\n\n# Extract the adjusted r-squared\nregression_adj_rsq = FamaFrench_fit.rsquared_adj\nprint(regression_adj_rsq)\n\n#0.8193910088585149\n\n'''The Fama-French 3 factor model fit well, \nraising the adjusted r-squared from 0.7943 to 0.8194, meaning that the model explains more of your portfolio variance. \nBut there's still room for improvement'''\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# p-values and coefficients","metadata":{}},{"cell_type":"code","source":"# Extract the p-value of the SMB factor\nsmb_pval = FamaFrench_fit.pvalues['SMB']\n\n# If the p-value is significant, print significant\nif smb_pval < 0.05:\n    significant_msg = 'significant'\nelse:\n    significant_msg = 'not significant'\n\n# Print the SMB coefficient\nsmb_coeff = FamaFrench_fit.params['SMB']\nprint(\"The SMB coefficient is \", smb_coeff, \" and is \", significant_msg)\n#The SMB coefficient is  -0.2621515274319269  and is  significant\n\n'''Your portfolio has a statistically significant negative exposure (-0.2621) to small-cap stocks\n- in other words - positive exposure to large caps!'''\n\n\n'''In the Fama-French factor model:\n\n- The HML factor is constructed by calculating the return of growth stocks, or stocks with high valuations, \nversus the return of value stocks.\n- The SMB factor is constructed by calculating the return of small-cap stocks, or stocks with small market capitalizations, \nversus the return of large-cap stocks.'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate your portfolio alpha\nportfolio_alpha = FamaFrench_fit.params['Intercept']\nprint(portfolio_alpha)\n\n# Annualize your portfolio alpha\nportfolio_alpha_annualized = ((1+portfolio_alpha)**252)-1\nprint(portfolio_alpha_annualized)\n\n'''\n0.0001832666520318351\n0.04726181730280854\n\nGreat! Your annualized portfolio alpha is 4.73% -- Efficient markets beware!\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The 5-factor model\n# In 2015, Fama and French extended their previous 3-factor model, adding two additional factors:\n\n**RMW: Profitability\nCMA: Investment**","metadata":{}},{"cell_type":"code","source":"# Import statsmodels.formula.api\nimport statsmodels.formula.api as smf \n\n# Define the regression formula\nFamaFrench5_model = smf.ols(formula='Portfolio_Excess ~ Market_Excess + SMB + HML + RMW + CMA ', data=FamaFrenchData)\n\n# Fit the regression\nFamaFrench5_fit = FamaFrench5_model.fit()\n\n# Extract the adjusted r-squared\nregression_adj_rsq = FamaFrench5_fit.rsquared_adj\nprint(regression_adj_rsq)\n\n'''0.8367245019225789'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Estimating tailrisk","metadata":{}},{"cell_type":"markdown","source":"**Historical drawdown**\n\n**The stock market tends to rise over time, but that doesn't mean that you won't have periods of drawdown. \nDrawdown can be measured as the percentage loss from the highest cumulative historical point.**\n\n","metadata":{}},{"cell_type":"code","source":"# Calculate the running maximum\nrunning_max = np.maximum.accumulate(cum_rets)\n\n# Ensure the value never drops below 1\nrunning_max[running_max<1] = 1\n\n# Calculate the percentage drawdown\ndrawdown = (cum_rets)/running_max - 1\n\n# Plot the results\ndrawdown.plot()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Value at Risk, often referred to as VaR, is a way to estimate the risk of a single day negative price movement. \nVaR can be measured for any given probability, or confidence level, but the most commonly quoted tend to be VaR(95) and VaR(99).**","metadata":{}},{"cell_type":"code","source":"# Calculate historical VaR(95)\nvar_95 = np.percentile(StockReturns_perc, 5)\nprint(var_95)\n\n# Sort the returns for plotting\nsorted_rets = sorted(StockReturns_perc)\n\n# Plot the probability of each sorted return quantile\nplt.hist(sorted_rets, normed=True)\n\n# Denote the VaR 95 quantile\nplt.axvline(x=var_95, color='r', linestyle='-', label=\"VaR 95: {0:.2f}%\".format(var_95))\nplt.show()\n\n#Very good! Historical VaR(95) = -3.61","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expected Shortfall, otherwise known as CVaR, or conditional value at risk, \nis simply the expected loss of the worst case scenarios of returns.**","metadata":{}},{"cell_type":"code","source":"# Historical CVaR 95\ncvar_95 = StockReturns_perc[StockReturns_perc<=var_95].mean()\nprint(cvar_95)\n\n# Sort the returns for plotting\nsorted_rets = sorted(StockReturns_perc)\n\n# Plot the probability of each return quantile\nplt.hist(sorted_rets, normed=True)\n\n# Denote the VaR 95 and CVaR 95 quantiles\nplt.axvline(x=var_95, color=\"r\", linestyle=\"-\", label='VaR 95: {0:.2f}%'.format(var_95))\nplt.axvline(x=cvar_95, color='b', linestyle='-', label='CVaR 95: {0:.2f}%'.format(cvar_95))\nplt.show()\n\n#-5.054143158346778\n\n'''\nNotice how the CVaR(95) of -5.05% was more extreme than the VaR(95) level?\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Changing VaR and CVaR quantiles\n****","metadata":{}},{"cell_type":"code","source":"# Historical VaR(90) quantiles\nvar_90 = np.percentile(StockReturns_perc, 10)\nprint(var_90)\n\n# Historical CVaR(90) quantiles\ncvar_90 = StockReturns_perc[StockReturns_perc<=var_90].mean()\nprint(cvar_90)\n\n# Plot to compare\nplot_hist()\n\n# -2.558512646965176\n# -4.043186770518807\n\n#The CVaR(90) is -4.04%, which is higher than the VaR(90) of -2.56%.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import norm from scipy.stats\nfrom scipy.stats import norm\n\n# Estimate the average daily return\nmu = np.mean(StockReturns)\n\n# Estimate the daily volatility\nvol = np.std(StockReturns)\n\n# Set the VaR confidence level\nconfidence_level = 0.05\n\n# Calculate Parametric VaR\nvar_95 = norm.ppf(confidence_level, mu, vol)\nprint('Mean: ', str(mu), '\\nVolatility: ', str(vol), '\\nVaR(95): ', str(var_95))\n\n'''\nMean:  -0.0002863895624021478 \nVolatility:  0.02188808712970886 \nVaR(95):  -0.03628908906473362\n\nThe parametric VaR(95) is -3.63%.\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The VaR(95) number calculated in previous exercises is simply the value at risk for a single day. To estimate the VaR for a longer time horizon, scale the value by the square root of time, similar to scaling volatility:**","metadata":{}},{"cell_type":"code","source":"# Aggregate forecasted VaR\nforecasted_values = np.empty([100, 2])\n\n# Loop through each forecast period\nfor i in range(0,100):\n    # Save the time horizon i\n    forecasted_values[i, 0] = i\n    # Save the forecasted VaR 95\n    forecasted_values[i, 1] = var_95* np.sqrt(i+1)\n    \n# Plot the results\nplot_var_scale()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A random walk simulation\n**Stochastic or random movements are used in physics to represent particle and fluid movements, in mathematics to describe fractal behavior, and in finance to describe stock market movements.**","metadata":{}},{"cell_type":"code","source":"# Set the simulation parameters\nmu = np.mean(StockReturns)\nvol = np.std(StockReturns)\nT = 252\nS0 = 10\n\n# Add one to the random returns\nrand_rets = np.random.normal(mu,vol,T) + 1\n\n# Forecasted random walk\nforecasted_values = rand_rets.cumprod()*S0\n\n# Plot the random walk\nplt.plot(range(0, T), forecasted_values)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**Monte-Carlo simulations are used to model a wide range of possibilities.**\n\n**Monte-Carlos can be constructed in many different ways, but all of them involve generating a large number of random variants of a given model, allowing a wide distribution of possible paths to be analyzed. This can allow you to build a comprehensive forecast of possibilities to sample from without a large amount of historical data.**","metadata":{}},{"cell_type":"code","source":"# Loop through 100 simulations\nfor i in range(100):\n\n    # Generate the random returns\n    rand_rets = np.random.normal(mu, vol, T) + 1\n    \n    # Create the Monte carlo path\n    forecasted_values = S0*(rand_rets).cumprod()\n    \n    # Plot the Monte Carlo path\n    plt.plot(range(T), forecasted_values)\n\n# Show the simulations\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregate the returns\nsim_returns = []\n\n# Loop through 100 simulations\nfor i in range(100):\n\n    # Generate the Random Walk\n    rand_rets = np.random.normal(mu, vol, T)\n    \n    # Save the results\n    sim_returns.append(rand_rets)\n\n# Calculate the VaR(99)\nvar_99 = np.percentile(sim_returns, 1)\nprint(\"Parametric VaR(99): \", round(100*var_99, 2),\"%\")","metadata":{},"execution_count":null,"outputs":[]}]}